# -*- coding: utf-8 -*-
"""chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1buMOy3F9RPL2SMre4kOu3MeoyIC0pURR
"""

pip install nltk scikit-learn

import nltk
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer

# Download NLTK resources if needed
nltk.download('punkt')
nltk.download('stopwords')
# Download the 'punkt_tab' resource
nltk.download('punkt_tab') # This line is added to fix the LookupError.

# Initialize the stemmer and stopwords list
stemmer = PorterStemmer()
stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    """
    Preprocess the text: tokenization, stopword removal, and stemming.
    """
    tokens = word_tokenize(text.lower())  # Convert to lowercase and tokenize
    filtered_tokens = [stemmer.stem(word) for word in tokens if word.isalnum() and word not in stop_words]
    return " ".join(filtered_tokens)

def load_responses(file_path):
    """
    Load question-response pairs from the data.txt file.
    """
    responses = []
    questions = []
    try:
        with open(file_path, 'r') as file:
            for line in file:
                if "=" in line:
                    question, answer = line.strip().split("=")
                    questions.append(preprocess_text(question))  # Preprocess question
                    responses.append(answer.strip())  # Keep response as is
    except FileNotFoundError:
        print(f"Error: The file {file_path} was not found.")
        return [], []

    return questions, responses

def chat(questions, responses):
    """
    Function to initiate chat and find the best response based on TF-IDF and cosine similarity.
    """
    print("Chatbot: Hello! Type 'exit' to end the chat.")

    # Create a TF-IDF vectorizer
    vectorizer = TfidfVectorizer()

    # Fit the vectorizer on the questions (training data)
    tfidf_matrix = vectorizer.fit_transform(questions)

    while True:
        user_input = input("You: ").strip()

        # Exit condition
        if user_input.lower() == "exit":
            print("Chatbot: Goodbye!")
            break

        # Preprocess user input
        user_input_preprocessed = preprocess_text(user_input)

        # Transform user input into TF-IDF vector
        user_input_vector = vectorizer.transform([user_input_preprocessed])

        # Compute cosine similarity between user input and all questions
        cosine_similarities = cosine_similarity(user_input_vector, tfidf_matrix)

        # Get the index of the most similar question
        most_similar_idx = np.argmax(cosine_similarities)

        # Return the corresponding response
        print(f"Chatbot: {responses[most_similar_idx]}")

# Load questions and responses from data.txt
questions, responses = load_responses("/content/data.txt")

# If valid data is loaded, start chatting
if questions and responses:
    chat(questions, responses)
else:
    print("Chatbot: No responses available. Please check the 'data.txt' file.")